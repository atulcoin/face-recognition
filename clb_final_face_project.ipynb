{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final face project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyObCH3849FRBSkbghILCvat",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atulcoin/face-recognition/blob/master/clb_final_face_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rskV1UqV3MM",
        "outputId": "c1abd305-8f31-4a63-c248-861faab7c89e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!pip install pafy\n",
        "!pip install imutils pafy youtube-dl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pafy in /usr/local/lib/python3.6/dist-packages (0.5.5)\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.6/dist-packages (0.5.3)\n",
            "Requirement already satisfied: pafy in /usr/local/lib/python3.6/dist-packages (0.5.5)\n",
            "Requirement already satisfied: youtube-dl in /usr/local/lib/python3.6/dist-packages (2020.9.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZqZyWkYWLYV"
      },
      "source": [
        "import imutils\n",
        "import cv2\n",
        "import pafy\n",
        "import youtube_dl\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYmvK5crWXQ3"
      },
      "source": [
        "url = \"https://www.youtube.com/watch?v=hoNb6HuNmU0\"\n",
        "vPafy = pafy.new(url)\n",
        "\n",
        "play = vPafy.getbest(preftype=\"mp4\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0bEq-4oWbaY",
        "outputId": "dd0bd685-6c29-4c3d-87b8-8170505eeac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "cap = cv2.VideoCapture(play.url)\n",
        "print(cap.isOpened()) # if in cap we have entered wrong file path then it will give false else true\n",
        "while(cap.isOpened()):    # TO CAPTURE FRAMES OF CAMERA TO VIEW AS VIDEO \n",
        "  #  print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # TO PRINT HEIGHT or property OF THE FRAME \n",
        "  #  print(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) # TO PRINT WIDTHE OF THE FRAME \n",
        "    face_dec = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "    ret, frame= cap.read()\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # here i am printing gray image as output\n",
        "    faces = face_dec.detectMultiScale(gray, scaleFactor =1.05, minNeighbors=5)\n",
        "\n",
        "    for x,y,w,h in faces:\n",
        "        gray = cv2.rectangle(gray, (x,y), (x+w,y+h), (0,255,0),2)\n",
        "        cv2_imshow(gray)\n",
        "    if cv2.waitKey(1) == 13:  #13 is the asci code of enter key\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b27ccdfe26d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# here i am printing gray image as output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_dec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaleFactor\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminNeighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/objdetect/src/cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'detectMultiScale'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0t07z1Gn_38"
      },
      "source": [
        "training of model with custom data set\n",
        "**bold text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91UpJplsrkJu",
        "outputId": "b281e8e6-19e2-4704-ef02-79d69cf63bca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ads9PHyrW2xR"
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "bpath = '/content/drive/My Drive/part1face'\n",
        "image_dir = os.path.join(bpath, \"train\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1iUs8KRpKoM",
        "outputId": "4f9cd42c-4f48-421e-f6d1-a81104734459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_label = []\n",
        "x_train = []\n",
        "\n",
        "#count = 0\n",
        "\n",
        "current_id=0\n",
        "label_id={}\n",
        "\n",
        "\n",
        "for root, dirs, files in os.walk(image_dir):\n",
        "  for file in files:\n",
        "    if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
        "      label = os.path.basename(root).replace(\" \",\"-\").lower() #we can replace os.path.dirname(path) with root also\n",
        "      path = os.path.join(root,file)\n",
        "            #print(label,path)\n",
        "            \n",
        "      if not label in label_id:\n",
        "        label_id[label] = current_id\n",
        "        current_id +=1\n",
        "        id_= label_id[label]\n",
        "        print(id_)\n",
        "        #img = cv2.imread(path, 1)\n",
        "        pil_image=  Image.open(path).convert(\"L\") # L to convert image in grey pil image is used to tell sysetem that the file in location is image file\n",
        "        image_arra=  np.array(pil_image,\"uint8\")\n",
        "            #print(image_arra)\n",
        "            \n",
        "        y_label.append(id_)\n",
        "        x_train.append(image_arra)\n",
        "y_label = np.asarray(y_label, dtype=np.int32)\n",
        "x_train = np.asarray(x_train, dtype=np.int32)\n",
        "#model = cv2.face.LBPHFaceRecognizer_create()\n",
        "\n",
        "#model.train(np.asarray(x_train), np.asarray(y_label))\n",
        "#with open(\"labels.pickle\", 'wb') as f:\n",
        "   # pickle.dump(label_id, f)\n",
        "print(\"train complete\")\n",
        "print(x_train)\n",
        "#model.save('save_face.xml')\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "train complete\n",
            "[[[128 133 139 ... 105 112 111]\n",
            "  [127 132 138 ... 105 109 109]\n",
            "  [128 132 138 ...  99 104 106]\n",
            "  ...\n",
            "  [ 55  59  68 ...  38  37  37]\n",
            "  [ 57  60  70 ...  38  38  38]\n",
            "  [ 58  61  70 ...  39  38  38]]\n",
            "\n",
            " [[ 55  51  47 ...  27  28  29]\n",
            "  [ 55  51  47 ...  26  28  28]\n",
            "  [ 55  52  49 ...  27  27  27]\n",
            "  ...\n",
            "  [ 32  32  32 ... 250 250 251]\n",
            "  [ 31  31  31 ... 249 250 251]\n",
            "  [ 32  31  31 ... 249 249 251]]\n",
            "\n",
            " [[ 36  36  36 ...  21  21  21]\n",
            "  [ 36  36  36 ...  20  20  20]\n",
            "  [ 36  36  36 ...  19  19  19]\n",
            "  ...\n",
            "  [ 32  30  29 ...   7   7   8]\n",
            "  [ 35  32  30 ...   7   8   8]\n",
            "  [ 37  35  32 ...   8   8   8]]\n",
            "\n",
            " [[ 31  31  31 ... 156 133 114]\n",
            "  [ 31  31  31 ... 158 133 112]\n",
            "  [ 32  31  31 ... 161 135 114]\n",
            "  ...\n",
            "  [255 255 255 ... 101 112 125]\n",
            "  [255 255 255 ...  93 102 108]\n",
            "  [255 255 255 ...  77  83 101]]\n",
            "\n",
            " [[142 142 122 ...  22  23  23]\n",
            "  [141 142 122 ...  22  23  23]\n",
            "  [139 140 120 ...  22  22  22]\n",
            "  ...\n",
            "  [ 13  13  13 ...  12  12  12]\n",
            "  [ 13  13  13 ...  11  11  11]\n",
            "  [ 13  13  13 ...  11  11  11]]\n",
            "\n",
            " [[ 36  37  37 ... 252 252 252]\n",
            "  [ 37  37  37 ... 252 252 252]\n",
            "  [ 37  37  37 ... 252 252 252]\n",
            "  ...\n",
            "  [ 73  73  74 ... 255 255 255]\n",
            "  [ 72  72  73 ... 255 255 255]\n",
            "  [ 72  72  73 ... 255 255 255]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiBwAb9G1C53"
      },
      "source": [
        "y_label = y_label.shuffle(10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWeW8J1itdIS",
        "outputId": "ee1c5b10-3621-4e1c-e828-9a654b287081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 200, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lsyB3hGvGU3",
        "outputId": "2127b14a-e6b3-4ebf-9a1a-9992ce6047bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvZRcAN6vTlR"
      },
      "source": [
        "x_train = np.array(x_train)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX31Lj50wbuX",
        "outputId": "10e7f7f3-9e6c-436a-98ba-94ba6c460de5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 200, 200, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIaRr6yPwlX6"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "y_label =y_label.astype('float32')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYIJX8u-x2el"
      },
      "source": [
        "x_train /= 255\n",
        "y_label /=255"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADVeTxUCx76u"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "import keras"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao5dUMe3y3l2"
      },
      "source": [
        "creating validation data set for validating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZDfg5ubyDqa"
      },
      "source": [
        "bpath = '/content/drive/My Drive/part1face'\n",
        "image_dir = os.path.join(bpath, \"validation\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml2qrf61y1lL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaW8wbVTyi4_",
        "outputId": "bba08a17-30c9-44c1-e66d-01c1068e5ba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_vali = []\n",
        "x_vali = []\n",
        "\n",
        "#count = 0\n",
        "\n",
        "current_id=0\n",
        "label_id={}\n",
        "\n",
        "\n",
        "for root, dirs, files in os.walk(image_dir):\n",
        "  for file in files:\n",
        "    if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
        "      label = os.path.basename(root).replace(\" \",\"-\").lower() #we can replace os.path.dirname(path) with root also\n",
        "      path = os.path.join(root,file)\n",
        "            #print(label,path)\n",
        "            \n",
        "      if not label in label_id:\n",
        "        label_id[label] = current_id\n",
        "        current_id +=1\n",
        "        id_= label_id[label]\n",
        "        print(id_)\n",
        "        #img = cv2.imread(path, 1)\n",
        "        pil_image=  Image.open(path).convert(\"L\") # L to convert image in grey pil image is used to tell sysetem that the file in location is image file\n",
        "        image_arra=  np.array(pil_image,\"uint8\")\n",
        "            #print(image_arra)\n",
        "            \n",
        "        y_vali.append(id_)\n",
        "        x_vali.append(image_arra)\n",
        "y_vali = np.asarray(y_vali, dtype=np.int32)\n",
        "x_vali = np.asarray(x_vali, dtype=np.int32)\n",
        "#model = cv2.face.LBPHFaceRecognizer_create()\n",
        "\n",
        "#model.train(np.asarray(x_train), np.asarray(y_label))\n",
        "#with open(\"labels.pickle\", 'wb') as f:\n",
        "   # pickle.dump(label_id, f)\n",
        "print(\"validation data complete\")\n",
        "print(x_vali)\n",
        "#model.save('save_face.xml')\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "validation data complete\n",
            "[[[128 133 139 ... 105 112 111]\n",
            "  [127 132 138 ... 105 109 109]\n",
            "  [128 132 138 ...  99 104 106]\n",
            "  ...\n",
            "  [ 55  59  68 ...  38  37  37]\n",
            "  [ 57  60  70 ...  38  38  38]\n",
            "  [ 58  61  70 ...  39  38  38]]\n",
            "\n",
            " [[ 55  51  47 ...  27  28  29]\n",
            "  [ 55  51  47 ...  26  28  28]\n",
            "  [ 55  52  49 ...  27  27  27]\n",
            "  ...\n",
            "  [ 32  32  32 ... 250 250 251]\n",
            "  [ 31  31  31 ... 249 250 251]\n",
            "  [ 32  31  31 ... 249 249 251]]\n",
            "\n",
            " [[ 36  36  36 ...  21  21  21]\n",
            "  [ 36  36  36 ...  20  20  20]\n",
            "  [ 36  36  36 ...  19  19  19]\n",
            "  ...\n",
            "  [ 32  30  29 ...   7   7   8]\n",
            "  [ 35  32  30 ...   7   8   8]\n",
            "  [ 37  35  32 ...   8   8   8]]\n",
            "\n",
            " [[ 31  31  31 ... 156 133 114]\n",
            "  [ 31  31  31 ... 158 133 112]\n",
            "  [ 32  31  31 ... 161 135 114]\n",
            "  ...\n",
            "  [255 255 255 ... 101 112 125]\n",
            "  [255 255 255 ...  93 102 108]\n",
            "  [255 255 255 ...  77  83 101]]\n",
            "\n",
            " [[142 142 122 ...  22  23  23]\n",
            "  [141 142 122 ...  22  23  23]\n",
            "  [139 140 120 ...  22  22  22]\n",
            "  ...\n",
            "  [ 13  13  13 ...  12  12  12]\n",
            "  [ 13  13  13 ...  11  11  11]\n",
            "  [ 13  13  13 ...  11  11  11]]\n",
            "\n",
            " [[ 36  37  37 ... 252 252 252]\n",
            "  [ 37  37  37 ... 252 252 252]\n",
            "  [ 37  37  37 ... 252 252 252]\n",
            "  ...\n",
            "  [ 73  73  74 ... 255 255 255]\n",
            "  [ 72  72  73 ... 255 255 255]\n",
            "  [ 72  72  73 ... 255 255 255]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDWvCQEyzmxr"
      },
      "source": [
        "x_vali = x_vali.astype('float32')\n",
        "y_vali =y_vali.astype('float32')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAf02oYQz4po"
      },
      "source": [
        "x_vali /= 255\n",
        "y_vali /=255"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT0FScOb10dY"
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDXoWAhG3O57",
        "outputId": "a405d7ed-4b38-48fa-f523-9953ab6b1f25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_label.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWqYhE493Vbr",
        "outputId": "710b3be0-d4c3-4fa0-fd50-02f41d2bfbff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 200, 200, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShGBSm2w3gl0",
        "outputId": "65beedd4-bda4-4ee8-99cd-5c36c6e67b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_vali.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 200, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXGCvh1U0xlr"
      },
      "source": [
        "input_size = 400\n",
        "output_size = 6\n",
        "hidden_layer_size = 100\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(200, 200)),\n",
        "        tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "        tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "       tf.keras.layers.Dense(output_size, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoUmQZkn1t8-",
        "outputId": "f33f9df0-ab78-48b2-9e89-ff56e8fdbfef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "model.fit(x_train, y_label, epochs=10, validation_data=(x_vali, y_vali), verbose =2)\n",
        "print (\"training complete\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 - 0s - loss: 71.4192 - accuracy: 0.1667 - val_loss: 18.0668 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 - 0s - loss: 2213.3047 - accuracy: 0.1667 - val_loss: 25.9176 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 - 0s - loss: 3744.0957 - accuracy: 0.1667 - val_loss: 14.3019 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 - 0s - loss: 2917.4622 - accuracy: 0.1667 - val_loss: 0.5151 - val_accuracy: 0.1667\n",
            "Epoch 5/10\n",
            "1/1 - 0s - loss: 1590.2587 - accuracy: 0.1667 - val_loss: 5.1903 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 - 0s - loss: 1851.3525 - accuracy: 0.1667 - val_loss: 5.8952 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 - 0s - loss: 593.6945 - accuracy: 0.6667 - val_loss: 8.0621 - val_accuracy: 0.1667\n",
            "Epoch 8/10\n",
            "1/1 - 0s - loss: 158.3786 - accuracy: 0.6667 - val_loss: 9.7786 - val_accuracy: 0.1667\n",
            "Epoch 9/10\n",
            "1/1 - 0s - loss: 71.7399 - accuracy: 0.6667 - val_loss: 10.9391 - val_accuracy: 0.1667\n",
            "Epoch 10/10\n",
            "1/1 - 0s - loss: 243.3251 - accuracy: 0.6667 - val_loss: 11.2938 - val_accuracy: 0.1667\n",
            "training complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9thQX-P42Apm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}